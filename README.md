<div align="center">
  <img src="logo-Photoroom.png" alt="Veda Logo" width="150">
  <h1>Veda - On-Device Voice Assistant</h1>
  <p>
    <strong>ğŸ¤– Advanced AI-powered voice assistant running entirely on-device</strong><br>
    Built with Swift and powered by Google's Gemma 2B CoreML models
  </p>
  
  <!-- Badges -->
  <p>
    <img src="https://img.shields.io/badge/iOS-16.0%2B-blue" alt="iOS 16.0+">
    <img src="https://img.shields.io/badge/Xcode-14.0%2B-blue" alt="Xcode 14.0+">
    <img src="https://img.shields.io/badge/Swift-5.9-orange.svg" alt="Swift 5.9">
    <img src="https://img.shields.io/badge/CoreML-Gemma%202B-green" alt="CoreML Gemma 2B">
    <img src="https://img.shields.io/badge/License-MIT-green" alt="License: MIT">
    <img src="https://img.shields.io/badge/Privacy-On%20Device-purple" alt="Privacy: On Device">
  </p>
  
  <p>
    <strong>ğŸ“± Real-time voice interaction â€¢ ğŸ™ï¸ Speech recognition â€¢ ğŸ”Š Text-to-speech â€¢ ğŸ’¬ Conversation management</strong>
  </p>
</div>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¯ **Core Capabilities**
- **ğŸ™ï¸ Voice Interaction**: Real-time speech-to-text with visual feedback
- **ğŸ¤– AI Responses**: Powered by Gemma 2B CoreML models  
- **ğŸ”Š Text-to-Speech**: Natural voice synthesis with customization
- **ğŸ’¬ Smart Conversations**: Context-aware dialogue management

</td>
<td width="50%">

### âš™ï¸ **Advanced Features**
- **ğŸ“± Modern UI**: Clean interface with haptic feedback
- **ğŸ”’ Privacy First**: All processing happens on-device
- **ğŸ“‚ Data Export**: Export conversations to Markdown
- **ğŸ¨ Beautiful Design**: Animated splash screen & smooth UX

</td>
</tr>
</table>

## ğŸš€ Quick Start

> **âš¡ Get Veda running in under 5 minutes!**

### Prerequisites

<table>
<tr>
<td><strong>ğŸ’» System</strong></td>
<td>macOS 12.0+, Xcode 14.0+</td>
</tr>
<tr>
<td><strong>ğŸ“± Device</strong></td>
<td>iOS 16.0+, iPhone 12+ recommended</td>
</tr>
<tr>
<td><strong>ğŸ’¾ Storage</strong></td>
<td>8GB+ free space (for models)</td>
</tr>
<tr>
<td><strong>ğŸŒ Network</strong></td>
<td>Internet required for initial model download</td>
</tr>
</table>

### ğŸ› ï¸ Installation

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/TVR28/On-Device-Voice-Assistant.git
cd On-Device-Voice-Assistant

# 2ï¸âƒ£ Download AI models (automated setup)
./setup_models.sh

# 3ï¸âƒ£ Open in Xcode
open VoiceFoundationApp/VoiceFoundationApp.xcodeproj

# 4ï¸âƒ£ Build & Run (âŒ˜+R) - Grant microphone permissions when prompted
```

> **ğŸ”¥ That's it! Veda is ready to chat with you.**

## ğŸ¤– AI Models

Veda uses Google's cutting-edge Gemma 2B models, optimized for Apple Silicon:

<table>
<tr>
<th>Model</th>
<th>Size</th>
<th>Precision</th>
<th>Use Case</th>
</tr>
<tr>
<td><strong>Gemma-2B-IT-Stateful-128</strong></td>
<td>~5GB</td>
<td>Full (128-bit)</td>
<td>Maximum quality responses</td>
</tr>
<tr>
<td><strong>Gemma-2B-IT-Stateful-4bit-128</strong></td>
<td>~1.4GB</td>
<td>Quantized (4-bit)</td>
<td>Faster inference, lower memory</td>
</tr>
</table>

**ğŸ”’ Privacy**: Models are stored in a private Hugging Face repository and run entirely on-device.

## ğŸ—ï¸ Architecture

<div align="center">
  <img src="flow-diagram.png" alt="Architecture Diagram" width="700">
</div>

### Core Components

| Component | Responsibility |
|-----------|----------------|
| **ContentView** | Main UI with voice interaction controls |
| **SpeechManager** | Speech recognition & text-to-speech synthesis |
| **MockLLMManager** | AI model inference & streaming responses |
| **ConversationManager** | Persistent conversation storage |
| **SettingsView** | Configuration & preferences |

## ğŸ›ï¸ Advanced Features

<details>
<summary><strong>ğŸ™ï¸ Voice Interaction</strong></summary>

- **Tap & Hold**: Record voice input with real-time feedback
- **Hands-free Mode**: Automatic voice activation
- **Custom TTS**: Adjustable speed, pitch, and voice selection
- **Smart Detection**: Automatic speech start/stop detection

</details>

<details>
<summary><strong>ğŸ’¬ Conversation Management</strong></summary>

- **Persistent History**: All conversations saved locally
- **Smart Export**: Export to Markdown with metadata
- **Custom Storage**: Choose your own storage location
- **Search & Filter**: Find conversations quickly

</details>

<details>
<summary><strong>âš™ï¸ Customization</strong></summary>

- **Model Selection**: Switch between 128-bit and 4-bit models
- **Voice Controls**: Fine-tune TTS parameters
- **Privacy Settings**: Control data retention
- **Performance Tuning**: Optimize for your device

</details>

## ğŸ“± System Requirements

<table>
<tr>
<td colspan="2" align="center"><strong>ğŸ”µ Minimum Requirements</strong></td>
</tr>
<tr>
<td><strong>iOS Version</strong></td>
<td>iOS 16.0 or later</td>
</tr>
<tr>
<td><strong>Device</strong></td>
<td>iPhone 12 or newer (A14 Bionic+)</td>
</tr>
<tr>
<td><strong>Storage</strong></td>
<td>8GB+ free space</td>
</tr>
<tr>
<td><strong>RAM</strong></td>
<td>6GB+ recommended</td>
</tr>
</table>

<table>
<tr>
<td colspan="2" align="center"><strong>ğŸŸ¢ Recommended Setup</strong></td>
</tr>
<tr>
<td><strong>iOS Version</strong></td>
<td>iOS 17.0 or later</td>
</tr>
<tr>
<td><strong>Device</strong></td>
<td>iPhone 14 Pro or newer</td>
</tr>
<tr>
<td><strong>Storage</strong></td>
<td>16GB+ free space</td>
</tr>
<tr>
<td><strong>Network</strong></td>
<td>Stable internet for setup</td>
</tr>
</table>

## ğŸ› ï¸ Development

### File Structure
```
VoiceFoundationApp/
â”œâ”€â”€ VoiceFoundationApp/
â”‚   â”œâ”€â”€ ContentView.swift              # ğŸ¨ Main UI
â”‚   â”œâ”€â”€ SpeechManager.swift            # ğŸ™ï¸ Speech processing
â”‚   â”œâ”€â”€ MockLLMManager.swift           # ğŸ¤– AI model interface
â”‚   â”œâ”€â”€ ConversationManager.swift     # ğŸ’¾ Data persistence
â”‚   â”œâ”€â”€ SettingsView.swift             # âš™ï¸ Configuration UI
â”‚   â”œâ”€â”€ SplashScreenView.swift         # âœ¨ Launch screen
â”‚   â”œâ”€â”€ Models.swift                   # ğŸ“‹ Data models
â”‚   â””â”€â”€ Assets.xcassets/               # ğŸ–¼ï¸ Images and icons
â”œâ”€â”€ VoiceFoundationAppTests/           # ğŸ§ª Unit tests
â””â”€â”€ VoiceFoundationAppUITests/         # ğŸ–±ï¸ UI tests
```

### Model Pipeline
The CoreML models undergo extensive optimization:

1. **ğŸ”„ Conversion**: PyTorch â†’ CoreML using Apple's tools
2. **âš¡ Optimization**: Neural Engine acceleration
3. **ğŸ“¦ Quantization**: Size/speed optimization
4. **ğŸ”„ Stateful Config**: Conversation context preservation

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **ğŸ´ Fork** the repository
2. **ğŸŒ¿ Create** your feature branch (`git checkout -b feature/AmazingFeature`)
3. **ğŸ’¾ Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **ğŸ“¤ Push** to the branch (`git push origin feature/AmazingFeature`)
5. **ğŸ”€ Open** a Pull Request

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

<table>
<tr>
<td align="center">
<strong>ğŸ¢ Google</strong><br>
Gemma model architecture
</td>
<td align="center">
<strong>ğŸ Apple</strong><br>
CoreML & Neural Engine
</td>
<td align="center">
<strong>ğŸ¤— Hugging Face</strong><br>
Model hosting platform
</td>
</tr>
</table>

## ğŸ“ Support & Troubleshooting

<details>
<summary><strong>ğŸ”§ Common Issues</strong></summary>

| Issue | Solution |
|-------|----------|
| **ğŸ“¥ Model Download Fails** | Check internet connection & storage space |
| **ğŸ”¨ Build Errors** | Ensure Xcode 14+ and iOS 16+ target |
| **ğŸŒ Slow Performance** | Try 4-bit quantized model |
| **ğŸ¤ Voice Not Working** | Check microphone permissions in Settings |

</details>

<details>
<summary><strong>ğŸ’¡ Performance Tips</strong></summary>

- **ğŸ”‹ Battery**: Use 4-bit model for longer battery life
- **ğŸš€ Speed**: Ensure sufficient free RAM (6GB+)
- **ğŸ“± Device**: iPhone 14 Pro+ for best experience
- **ğŸ”Š Audio**: Use wired headphones for best voice recognition

</details>

---

<div align="center">
  <p>
    <strong>Made with â¤ï¸ by the Veda Team</strong><br>
    <sub>Bringing AI conversations to your pocket, privately and securely</sub>
  </p>
  
  <p>
    <a href="https://github.com/TVR28/On-Device-Voice-Assistant/issues">ğŸ› Report Bug</a> â€¢
    <a href="https://github.com/TVR28/On-Device-Voice-Assistant/issues">ğŸ’¡ Request Feature</a> â€¢
    <a href="https://github.com/TVR28/On-Device-Voice-Assistant/discussions">ğŸ’¬ Discussions</a>
  </p>
  
  <p>
    <strong>â­ Star this repo if you found it helpful!</strong>
  </p>
</div> 